{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d73fc77",
   "metadata": {},
   "source": [
    "ğŸ§  What is KNN Classification?\n",
    "ğŸ”· KNN stands for:\n",
    "K-Nearest Neighbors\n",
    "\n",
    "Itâ€™s a supervised machine learning algorithm used for classification and regression, but it is mostly used for classification tasks.\n",
    "\n",
    "ğŸŒ± Intuition: How does KNN work?\n",
    "Imagine you're trying to predict what kind of flower a new sample is based on its features (like petal and sepal length/width).\n",
    "KNN says:\n",
    "\n",
    "\"Let me look at the K closest existing flowers (neighbors) to this one.\n",
    "Whichever class (species) is most common among themâ€¦ thatâ€™s what Iâ€™ll predict!\"\n",
    "\n",
    "ğŸªœ Steps Behind the Scenes\n",
    "âœ… You provide a labeled dataset (features + correct class labels).\n",
    "\n",
    "âœ… For a new, unseen data point:\n",
    "\n",
    "It measures the distance (usually Euclidean) from this point to all other training points.\n",
    "\n",
    "âœ… It selects the K closest neighbors (e.g., K=3).\n",
    "\n",
    "âœ… It checks what class they belong to.\n",
    "\n",
    "âœ… The majority class among those K neighbors is assigned as the prediction.\n",
    "\n",
    "ğŸ” Example (Visual Imagination)\n",
    "Letâ€™s say youâ€™re classifying a new flower ğŸŒ¸ using K=3:\n",
    "\n",
    "The new flower is near:\n",
    "\n",
    "2 Setosa ğŸŒ¸\n",
    "\n",
    "1 Versicolor ğŸŒº\n",
    "\n",
    "ğŸ‘‰ Since Setosa is the majority (2/3), KNN will classify it as Setosa.\n",
    "\n",
    "ğŸ”¢ What does \"K\" mean?\n",
    "\"K\" is the number of neighbors to consider.\n",
    "\n",
    "Itâ€™s a hyperparameter that you can tweak.\n",
    "\n",
    "A small K = more sensitive to noise, but captures local patterns.\n",
    "\n",
    "A large K = more stable, but might lose finer detail.\n",
    "\n",
    "ğŸ“Œ Common practice: try several K values (like 1 to 20) and see which gives best accuracy.\n",
    "\n",
    "ğŸ§® What distance is used?\n",
    "Most common: Euclidean distance\n",
    "\n",
    "Distance\n",
    "=\n",
    "(\n",
    "ğ‘¥\n",
    "1\n",
    "âˆ’\n",
    "ğ‘¥\n",
    "2\n",
    ")\n",
    "2\n",
    "+\n",
    "(\n",
    "ğ‘¦\n",
    "1\n",
    "âˆ’\n",
    "ğ‘¦\n",
    "2\n",
    ")\n",
    "2\n",
    "+\n",
    "â€¦\n",
    "Distance= \n",
    "(x \n",
    "1\n",
    "â€‹\n",
    " âˆ’x \n",
    "2\n",
    "â€‹\n",
    " ) \n",
    "2\n",
    " +(y \n",
    "1\n",
    "â€‹\n",
    " âˆ’y \n",
    "2\n",
    "â€‹\n",
    " ) \n",
    "2\n",
    " +â€¦\n",
    "â€‹\n",
    " \n",
    "Others: Manhattan, Minkowski, etc. (can be changed in sklearn)\n",
    "\n",
    "âœ… Pros of KNN:\n",
    "Simple and intuitive\n",
    "\n",
    "No training time (lazy learner)\n",
    "\n",
    "Works well with small datasets\n",
    "\n",
    "âŒ Cons of KNN:\n",
    "Slow with large datasets (needs to compute distance to every point)\n",
    "\n",
    "Sensitive to irrelevant features\n",
    "\n",
    "Needs feature scaling (important!)\n",
    "\n",
    "Sensitive to noisy data\n",
    "\n",
    "ğŸ§© KNN vs Other Classifiers:\n",
    "Feature\tKNN\tLogistic Regression / SVM\n",
    "Learning Style\tLazy (no real training)\tEager (learns a model)\n",
    "Decision Boundaries\tNon-linear, local\tCan be linear or non-linear\n",
    "Interpretability\tEasy to understand visually\tHarder to explain sometimes\n",
    "\n",
    "ğŸ§  Summary:\n",
    "KNN is like asking your neighbors for advice!\n",
    "It makes predictions based on how similar something is to things it has already seen.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
